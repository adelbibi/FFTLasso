{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The following code solves the LASSO problem in the Fourier Domain.\n",
    "\n",
    "The LASSO:\n",
    "$\\|\\mathbf{A} \\mathbf{c} - \\mathbf{b} \\|_2^2 + \\lambda \\|\\mathbf{c} \\|_1$\n",
    "\n",
    "This is a toy example on how large dictionaries $\\mathbf{A}$ can be distrubted over multiple GPUs. In general tensorflow is significently slower than many other optinos but it is particularly handy for prototyping. This is only a demonstration on the applicability of solving such large sclae problems in a GPU distributed fashion.\n",
    "\n",
    "Refer to \"FFTLasso: Large-Scale LASSO in The Fourier Domain\" for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Regularization Parameter Initialization\n",
    "\n",
    "Read data from disk, or simply generate your own gaussian dictionary (A) and test sample (b). Also, the choice of the regularization parameter is set ehre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reading data from disc\n",
    "# matA = spio.loadmat('A.mat')\n",
    "# matb = spio.loadmat('b.mat')\n",
    "# A = matA['A']\n",
    "# b = matb['b']\n",
    "# m,n = A.shape\n",
    "# print(m,n)\n",
    "\n",
    "a = np.arange(20) + 1\n",
    "b = np.arange(21,41)\n",
    "A = np.array([a,b])\n",
    "b = np.array([[1],[2]]).astype(np.float32)\n",
    "m, n = A.shape\n",
    "\n",
    "reg_param = np.array(1e-2).astype(np.float32) #regularization \\lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization parameters\n",
    "\n",
    "In here we initilize the ADMM parameters:\n",
    "\n",
    "1) Maximum number of iterations (max_iters)\n",
    "\n",
    "2) Stopping criterion based on the standard deviation of the last 5 objective values (threshold)\n",
    "\n",
    "3) Update of the dual variables using nesterovs method (Q, init_rho)\n",
    "\n",
    "4) The amound at which the augmentation constant is increased learning_rate (plays role in overall ADMM iteration count)\n",
    "\n",
    "5) The constants regarding nesterovs update and how much is it updated in every iter (init_gamma_val, gamma_factor)\n",
    "\n",
    "6) Every how many iterations do we carry out the updates to rho, init_gamma_cal (inc_iter)\n",
    "\n",
    "7) Maximum permittable rho (upper_limit_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opt_parameters():\n",
    "    max_iters = 1000 #max num iterations \n",
    "    threshold = 1e-8  #stopping criterion\n",
    "    #Nesterov's accelaration\n",
    "    Q = 30;\n",
    "    init_qfac=np.array((np.sqrt(Q)-1)/(np.sqrt(Q)+1)).astype(np.float32) \n",
    "    init_rho  = np.array(1).astype(np.float32) #initial rho\n",
    "    learning_rate = np.array(1).astype(np.float32) #increasing rate of rho\n",
    "    upper_limit_rho = 2000\n",
    "    inc_iter = 1     #upper bound on rho\n",
    "    init_gamma_val = np.array(1).astype(np.float32)  #initial gamma value\n",
    "    gamma_factor = 1 #increasing rate of gamma\n",
    "    \n",
    "    return (max_iters, threshold, init_qfac, init_rho, learning_rate, init_gamma_val, \n",
    "            gamma_factor, inc_iter, upper_limit_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class of the FFTLasso solver\n",
    "\n",
    "The class FFTLasso has the following methods:\n",
    "\n",
    "1) _initialize: initializes the variables in the optimization along with the overhead data that is used only once.\n",
    "\n",
    "5) fill_feed_dict: collects all the variables output of the optimization into a dictioray to be fed again to the network\n",
    "\n",
    "3) compute_cost: computes the objective value\n",
    "\n",
    "2) _graph: constructs the bulk of the graph for the optimization\n",
    "\n",
    "4) solve: solves the optimization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TFSolver(object):\n",
    "    def __init__(self, gpus=1):\n",
    "        self._gpus = gpus\n",
    "        \n",
    "################################################################\n",
    "                    #Initlize the variables\n",
    "################################################################\n",
    "\n",
    "    def _initialize(self, A, b, rho):\n",
    "        #break A_into piaces\n",
    "        A_all = self.break_A_pieces(A,self._gpus)\n",
    "        n_new = int(A.shape[1]/self._gpus)\n",
    "        #dual variable intialization in Foureri Domain\n",
    "        b_hat_conj = (np.fft.ifft(b.T).T).astype(np.complex64)\n",
    "        init_psi_hat_conj = (np.fft.ifft(np.zeros([m,1]).T).T).astype(np.complex64)\n",
    "        A_hat = [None] * self._gpus\n",
    "        A_hat_conj = [None] * self._gpus\n",
    "        corr_A_lists = [None] * self._gpus\n",
    "        init_theta = [None] * self._gpus\n",
    "        init_gamma = [None] * self._gpus\n",
    "        temp = [None] * self._gpus\n",
    "        init_zeta = [None] * self._gpus\n",
    "        \n",
    "        for i in range(self._gpus):\n",
    "            #Data related initialization\n",
    "            A_hat[i] = (np.fft.fft(A_all[i].T).T).astype(np.complex64)\n",
    "            A_hat_conj[i] = (np.fft.ifft(A_all[i].T).T).astype(np.complex64) # = np.conj(A_hat)/m\n",
    "             #constraints variable intilization\n",
    "            init_theta[i] = (np.zeros([m*n_new,1])).astype(np.float32)\n",
    "             #primal variable inilization\n",
    "            init_gamma[i] = (np.zeros([m*n_new,1])).astype(np.float32)\n",
    "            #init zeta\n",
    "            temp[i] = np.real(np.reshape(np.fft.fft((A_hat[i]*init_psi_hat_conj).T).T,(m*n_new,1))).astype(np.float32)\n",
    "            init_zeta[i] = (temp[i] + init_theta[i] + (init_gamma[i]))\n",
    "            \n",
    "        init_gamma_out = (np.zeros([n,1])).astype(np.float32)\n",
    "        mask_update = np.ones([m,n]).astype(np.float32)\n",
    "        mask_update[0] = 0\n",
    "        mask_update = np.split(mask_update,self._gpus,1)\n",
    "        corr_A = np.array(np.zeros([m,1]).T).T\n",
    "        for i in range(self._gpus):\n",
    "            corr_A = corr_A + np.reshape((np.real(np.sum(A_hat[i]*A_hat_conj[i],1))),(-1,1))\n",
    "            mask_update[i] = np.reshape(mask_update[i].T,(-1,1))\n",
    "            \n",
    "        \n",
    "        if(self._gpus > 1):\n",
    "            e = np.array(init_zeta)-np.array(init_theta)-np.array(init_gamma)\n",
    "            e_hat_conj  =(np.fft.ifft(np.reshape(e,(n,m)))).T  \n",
    "            ccc = np.array(A_hat_conj)\n",
    "            Ahat_conj_complete = ccc.reshape(ccc.shape[1],ccc.shape[0]*ccc.shape[2])\n",
    "            upper = np.reshape(np.sum(Ahat_conj_complete* np.array(e_hat_conj),axis=1),(m,1)) + b_hat_conj\n",
    "            lower = (rho * np.array(corr_A)) + 1.0\n",
    "            init_psi_hat_conj = upper / lower \n",
    "        else:\n",
    "            e = np.array(init_zeta)-np.array(init_theta)-np.array(init_gamma)\n",
    "            e_hat_conj  =(np.fft.ifft(np.reshape(e,(n,m)))).T  \n",
    "            upper = np.reshape(np.sum(np.reshape(np.array(A_hat_conj)* np.array(e_hat_conj),(m,n_new)),axis = 1),(-1,1)) + b_hat_conj\n",
    "            lower = (rho * np.array(corr_A)) + 1.0\n",
    "            init_psi_hat_conj = upper / lower\n",
    "            \n",
    "\n",
    "        diff_value = np.inf #error difference  \n",
    "    \n",
    "        \n",
    "        return(A_hat, corr_A, b_hat_conj, init_psi_hat_conj, init_theta, init_zeta, init_gamma, \n",
    "               init_gamma_out, mask_update)\n",
    "    \n",
    "################################################################\n",
    "        #Collects all variables into a dictionary\n",
    "################################################################\n",
    "    \n",
    "    \n",
    "    def fill_feed_dict(self,values):\n",
    "        feed_dict = { }\n",
    "        for i in range(self._gpus):\n",
    "            feed_dict[self.psi_hat_conj[i]] =  values[\"psi_hat_conj\"]\n",
    "            feed_dict[self.theta[i]] =  values[\"theta\"][i]\n",
    "            feed_dict[self.zeta[i]] =  values[\"zeta\"][i]\n",
    "            feed_dict[self.gamma[i]] =  values[\"gamma\"][i]\n",
    "            feed_dict[self.rho[i]] =  values[\"rho\"][0]\n",
    "            feed_dict[self.gamma_val[i]] =  values[\"gamma_val\"][0]\n",
    "\n",
    "        return feed_dict\n",
    "    \n",
    "################################################################\n",
    "        #Break bulky dictionary to pieces\n",
    "################################################################    \n",
    "    def break_A_pieces(self, A,num_gpus):\n",
    "        return np.split(A,num_gpus,1)\n",
    "\n",
    "################################################################\n",
    "        #Computes objectove value\n",
    "################################################################    \n",
    "    \n",
    "    def compute_cost(self, A,b,c,lamb):\n",
    "        m,n = A.shape\n",
    "        c = np.reshape(np.array(c),(m*n,1))\n",
    "        c=np.real(c[::m]/m)\n",
    "        return 0.5*(np.sum((np.dot(A,c) - b)**2)) + lamb*np.sum(np.abs(c))\n",
    "    \n",
    "################################################################\n",
    "        #Bulding the graph of 1 iteration\n",
    "################################################################   \n",
    "    \n",
    "    def _graph(self, init_A, init_b, init_A_hat, init_corr_aa, init_b_hat_conj, init_theta, init_zeta, \n",
    "               init_gamma, init_gamma_out, init_lamb, init_qfac, init_rho, init_gamma_val, init_mask_update):\n",
    "\n",
    "        self.psi_hat_conj = [None]*self._gpus\n",
    "        self.theta = [None]*self._gpus\n",
    "        self.zeta = [None]*self._gpus\n",
    "        self.gamma = [None]*self._gpus\n",
    "        self.gamma_out = [None]*self._gpus\n",
    "        self.rho = [None]*self._gpus\n",
    "        self.gamma_val = [None]*self._gpus\n",
    "\n",
    "        self.theta_o = [None]*self._gpus\n",
    "        self.zeta_o = [None]*self._gpus\n",
    "        self.gamma_o = [None]*self._gpus\n",
    "        self.gamma_out_o = [None]*self._gpus\n",
    "        self.rho_o = [None]*self._gpus\n",
    "        self.gamma_val_o = [None]*self._gpus\n",
    "        self.upper_o = [None]*self._gpus\n",
    "\n",
    "        n_new = int(init_A.shape[1]/self._gpus)\n",
    "        m_new = int(init_A.shape[0])\n",
    "        \n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():      \n",
    "            for i in range(self._gpus):\n",
    "                print(\"################################################################\")\n",
    "                with tf.device('/gpu:' + str(i)):           \n",
    "                    with tf.variable_scope('constants_'+str(i)):\n",
    "                        print(\"Transfering Constant Data to GPU\" + str(i), end=\"\")\n",
    "                        A_hat = tf.constant(init_A_hat[i],tf.complex64, name='A_hat')\n",
    "                        mask_update = tf.constant(init_mask_update[i],tf.float32, name = 'mask')\n",
    "                        lamb = tf.constant(init_lamb,tf.float32, name = 'lambda')\n",
    "                        qfac = tf.constant(init_qfac, name = 'Nesterovs_qfac')\n",
    "                        corr_A = tf.constant(init_corr_aa, tf.float32, name='corr_aa')\n",
    "                        b = tf.constant(init_b,tf.float32, name = 'b')\n",
    "                        b_hat_conj = tf.constant(init_b_hat_conj, tf.complex64, name='b_hat_conj')\n",
    "                        print(\": Done.\")\n",
    "                        \n",
    "                    with tf.variable_scope('variables_inputs_pl_'+str(i)):\n",
    "                        print(\"Initlization Place Holders on GPU\"  + str(i), end=\"\")\n",
    "                        self.psi_hat_conj[i] = tf.placeholder(tf.complex64, name = 'pl_psi_hat_conj')\n",
    "                        self.theta[i] = tf.placeholder(tf.float32, name = 'pl_theta')\n",
    "                        self.zeta[i] = tf.placeholder(tf.float32,  name = 'pl_zeta')\n",
    "                        self.gamma[i] = tf.placeholder(tf.float32, name = 'pl_gamma')\n",
    "                        self.rho[i] = tf.placeholder(tf.float32, name = 'pl_rho')            \n",
    "                        self.gamma_val[i] = tf.placeholder(tf.float32, name = 'pl_gamma_val')\n",
    "                        print(\": Done.\")\n",
    "                        \n",
    "                    with tf.variable_scope('variables_outputs_pl_'+str(i)):  \n",
    "                        self.theta_o[i] = self.theta[i] \n",
    "                        self.zeta_o[i] = self.zeta[i] \n",
    "                        self.gamma_o[i] = self.gamma[i] \n",
    "                        self.rho_o[i] = self.rho[i] \n",
    "                        self.gamma_val_o[i] = self.gamma_val[i]    \n",
    "                        \n",
    "                print(\"Generating Compute Graph on GPU\"  + str(i), end=\"\")\n",
    "                #theta_o update\n",
    "                with tf.name_scope('Theta_Update'):\n",
    "                    temp = tf.real(tf.reshape(tf.fft(tf.transpose(tf.multiply(A_hat, self.psi_hat_conj[i]))),(m_new*n_new,1)))\n",
    "                    self.theta_o[i] = self.zeta_o[i]-self.gamma_o[i]/self.rho_o[i]- temp\n",
    "                    self.theta_o[i] = self.theta_o[i] * mask_update\n",
    "\n",
    "                #zeta_o update\n",
    "                with tf.name_scope('Zeta_Update'):\n",
    "                    self.zeta_o[i] = temp+(self.theta_o[i])+(self.gamma_o[i]/self.rho_o[i])\n",
    "                    self.zeta_o[i] = tf.minimum(lamb,tf.abs(self.zeta_o[i])) * tf.sign(self.zeta_o[i])\n",
    "    \n",
    "    \n",
    "                #gamma_o update\n",
    "                with tf.name_scope('Gamma_Update'):\n",
    "                    gamma0_o=self.gamma_o[i];\n",
    "                    self.gamma_o[i] = (self.gamma_o[i] + (self.gamma_val_o[i]*self.rho_o[i])*( temp + (self.theta_o[i])-self.zeta_o[i]))\n",
    "                    self.gamma_o[i]=(1+qfac)*self.gamma_o[i]-qfac*gamma0_o; \n",
    "                    tf.summary.histogram('Gamm_Output', self.gamma_o[i])\n",
    "\n",
    "                #Psi update\n",
    "                with tf.name_scope('Upper_update_for_CPUPsi'):\n",
    "                    e = tf.cast(self.rho_o[i]*self.zeta_o[i]-self.rho_o[i]*self.theta_o[i]-self.gamma_o[i],tf.complex64)\n",
    "                    e_hat_conj  = tf.transpose(tf.ifft(tf.reshape(e,(n_new,m_new))))  \n",
    "#                     self.upper_o[i] = tf.reshape(tf.reduce_sum(A_hat_conj* e_hat_conj,1),[m_new,1])\n",
    "                    self.upper_o[i] = tf.reshape(tf.reduce_sum(tf.conj(A_hat)/m_new* e_hat_conj,1),[m_new,1])\n",
    "\n",
    "                print(\": Done.\")\n",
    "                    \n",
    "                    \n",
    "                self.merged = tf.summary.merge_all()\n",
    "                \n",
    "        print(\"################################################################\")\n",
    "   \n",
    "        outputs = {\"theta\": self.theta_o,\n",
    "                    \"zeta\": self.zeta_o,\n",
    "                    \"gamma\": self.gamma_o,\n",
    "                    \"rho\": self.rho_o,\n",
    "                    \"gamma_val\": self.gamma_val_o,\n",
    "                    \"upper\": self.upper_o,\n",
    "                  }\n",
    "\n",
    "        return graph,outputs    \n",
    "    \n",
    "################################################################\n",
    "                #Solving the Lasso\n",
    "################################################################         \n",
    "\n",
    "    def solve(self, A, b, reg_param, max_iters, threshold, \n",
    "                                  qfac, rho, learning_rate, \n",
    "                                  gamma_val, gamma_factor,inc_iter, upper_limit_rho):\n",
    "        \n",
    "        \n",
    "        (A_hat, corr_A, b_hat_conj, init_psi_hat_conj, theta, zeta, gamma, gamma_out, \n",
    "         mask_update) = self._initialize(A, b, rho)        \n",
    "        #Done initlization\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        print('Graph Generation ...')    \n",
    "        graph, outputs_nodes = self._graph(A, b, A_hat, corr_A, b_hat_conj, \n",
    "                                           theta, zeta, gamma, gamma_out, reg_param, \n",
    "                                           qfac, rho, gamma_val, mask_update)\n",
    "        \n",
    "        \n",
    "        init_values = {\"psi_hat_conj\": init_psi_hat_conj,\n",
    "                        \"theta\": theta,\n",
    "                        \"zeta\": zeta,\n",
    "                        \"gamma\": gamma,\n",
    "                        \"rho\": [rho],\n",
    "                        \"gamma_val\": [gamma_val],\n",
    "                        }\n",
    "        \n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            iteration_writer = tf.summary.FileWriter('./logs/1', sess.graph)\n",
    "            \n",
    "            # first iteration:\n",
    "            feed_dict = self.fill_feed_dict(init_values) \n",
    "            output_results = sess.run(outputs_nodes, feed_dict=feed_dict)            \n",
    "            cost = [self.compute_cost(A,b,output_results[\"gamma\"],reg_param)]\n",
    "            print(\"+ Iter: \", 1, 'Cost: ', cost[-1])\n",
    "                \n",
    "            # CPU for each upper and rho get phi_hat_conj for all gpus\n",
    "            sum_upper = np.zeros_like(output_results[\"upper\"][0]) + b_hat_conj\n",
    "            for upper in output_results[\"upper\"]:\n",
    "                sum_upper += upper\n",
    "            \n",
    "            lower = (output_results[\"rho\"][0]*corr_A) + 1.0\n",
    "            output_results[\"psi_hat_conj\"] = sum_upper / lower\n",
    "            \n",
    "################################################################\n",
    "                #Main Loop\n",
    "################################################################  \n",
    "            start_time = time.time()\n",
    "            for iteration in range(2,max_iters+1):\n",
    "                feed_dict = self.fill_feed_dict(output_results)\n",
    "                summary_new, output_results = sess.run([self.merged,outputs_nodes], feed_dict=feed_dict)\n",
    "                iteration_writer.add_summary(summary_new,iteration)\n",
    "                \n",
    "                # CPU for each upper and rho get phi_hat_conj for all gpus\n",
    "                sum_upper = np.zeros_like(output_results[\"upper\"][0]) + b_hat_conj\n",
    "                for upper in output_results[\"upper\"]:\n",
    "                    sum_upper += upper\n",
    "                lower = (np.array(output_results[\"rho\"][0])*corr_A)+ 1.0\n",
    "                output_results[\"psi_hat_conj\"] = sum_upper / lower\n",
    "\n",
    "                if iteration % 1 == 0:\n",
    "                    cost.append(self.compute_cost(A,b,output_results[\"gamma\"],reg_param))  \n",
    "                    print(\"+ Iter: \", iteration, 'Cost: ', cost[-1])\n",
    "                    \n",
    "                    if(np.std(np.array(cost[-5:])) < threshold):\n",
    "                        break\n",
    "                        \n",
    "                    if  iteration % inc_iter == 0:\n",
    "                        if(output_results[\"rho\"][0] <= upper_limit_rho):\n",
    "                            output_results[\"rho\"] = [output_results[\"rho\"][0]*learning_rate] * self._gpus\n",
    "  \n",
    "                    \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Total time in seconds: ', elapsed_time)\n",
    "        return output_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code\n",
    "\n",
    "- Specify the number of GPUs as input to TFSolver(.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Generation ...\n",
      "################################################################\n",
      "Transfering Constant Data to GPU0: Done.\n",
      "Initlization Place Holders on GPU0: Done.\n",
      "Generating Compute Graph on GPU0: Done.\n",
      "################################################################\n",
      "+ Iter:  1 Cost:  2.5\n",
      "+ Iter:  2 Cost:  0.466960894456\n",
      "+ Iter:  3 Cost:  0.111377564381\n",
      "+ Iter:  4 Cost:  0.00388653625561\n",
      "+ Iter:  5 Cost:  0.00557255851492\n",
      "+ Iter:  6 Cost:  0.00732937397269\n",
      "+ Iter:  7 Cost:  0.00247674659784\n",
      "+ Iter:  8 Cost:  0.00233350916786\n",
      "+ Iter:  9 Cost:  0.00166167073158\n",
      "+ Iter:  10 Cost:  0.00143436536159\n",
      "+ Iter:  11 Cost:  0.00182500788552\n",
      "+ Iter:  12 Cost:  0.00125435554097\n",
      "+ Iter:  13 Cost:  0.00128535423835\n",
      "+ Iter:  14 Cost:  0.00132887283472\n",
      "+ Iter:  15 Cost:  0.00152416719889\n",
      "+ Iter:  16 Cost:  0.000995299385975\n",
      "+ Iter:  17 Cost:  0.000942941050181\n",
      "+ Iter:  18 Cost:  0.000932455477586\n",
      "+ Iter:  19 Cost:  0.0012649946578\n",
      "+ Iter:  20 Cost:  0.00125366462538\n",
      "+ Iter:  21 Cost:  0.0012128208153\n",
      "+ Iter:  22 Cost:  0.000777641621735\n",
      "+ Iter:  23 Cost:  0.000848127666471\n",
      "+ Iter:  24 Cost:  0.000772231018331\n",
      "+ Iter:  25 Cost:  0.000746228007018\n",
      "+ Iter:  26 Cost:  0.000955981828705\n",
      "+ Iter:  27 Cost:  0.00113855433458\n",
      "+ Iter:  28 Cost:  0.00111185971085\n",
      "+ Iter:  29 Cost:  0.00090656615722\n",
      "+ Iter:  30 Cost:  0.000748614911636\n",
      "+ Iter:  31 Cost:  0.00067791277174\n",
      "+ Iter:  32 Cost:  0.000659393381121\n",
      "+ Iter:  33 Cost:  0.000664398396235\n",
      "+ Iter:  34 Cost:  0.00066853987546\n",
      "+ Iter:  35 Cost:  0.000748378067702\n",
      "+ Iter:  36 Cost:  0.000641457515156\n",
      "+ Iter:  37 Cost:  0.000633128089923\n",
      "+ Iter:  38 Cost:  0.000654350790268\n",
      "+ Iter:  39 Cost:  0.000738438871692\n",
      "+ Iter:  40 Cost:  0.000887452950131\n",
      "+ Iter:  41 Cost:  0.000841940896013\n",
      "+ Iter:  42 Cost:  0.000764361430348\n",
      "+ Iter:  43 Cost:  0.000652805375942\n",
      "+ Iter:  44 Cost:  0.000604624206905\n",
      "+ Iter:  45 Cost:  0.000586581937239\n",
      "+ Iter:  46 Cost:  0.000583995003492\n",
      "+ Iter:  47 Cost:  0.00058963386331\n",
      "+ Iter:  48 Cost:  0.000609725607681\n",
      "+ Iter:  49 Cost:  0.000632698231278\n",
      "+ Iter:  50 Cost:  0.000644609623656\n",
      "+ Iter:  51 Cost:  0.000635044257422\n",
      "+ Iter:  52 Cost:  0.00061308288735\n",
      "+ Iter:  53 Cost:  0.000590199724701\n",
      "+ Iter:  54 Cost:  0.000574563990172\n",
      "+ Iter:  55 Cost:  0.000566287219606\n",
      "+ Iter:  56 Cost:  0.000563585252964\n",
      "+ Iter:  57 Cost:  0.00056460877049\n",
      "+ Iter:  58 Cost:  0.000567507303341\n",
      "+ Iter:  59 Cost:  0.000569396197487\n",
      "+ Iter:  60 Cost:  0.000567938548297\n",
      "+ Iter:  61 Cost:  0.000562728698638\n",
      "+ Iter:  62 Cost:  0.000555441801577\n",
      "+ Iter:  63 Cost:  0.000535469863634\n",
      "+ Iter:  64 Cost:  0.000655101752075\n",
      "+ Iter:  65 Cost:  0.000664750717945\n",
      "+ Iter:  66 Cost:  0.000650799805588\n",
      "+ Iter:  67 Cost:  0.000553719175124\n",
      "+ Iter:  68 Cost:  0.000531983888392\n",
      "+ Iter:  69 Cost:  0.000594248001301\n",
      "+ Iter:  70 Cost:  0.000675831238762\n",
      "+ Iter:  71 Cost:  0.000724748419403\n",
      "+ Iter:  72 Cost:  0.000691589683932\n",
      "+ Iter:  73 Cost:  0.000622331368784\n",
      "+ Iter:  74 Cost:  0.000557257354404\n",
      "+ Iter:  75 Cost:  0.000528990060548\n",
      "+ Iter:  76 Cost:  0.000528229377401\n",
      "+ Iter:  77 Cost:  0.000532717488364\n",
      "+ Iter:  78 Cost:  0.000530031281\n",
      "+ Iter:  79 Cost:  0.000524854396358\n",
      "+ Iter:  80 Cost:  0.00052865871714\n",
      "+ Iter:  81 Cost:  0.000544605449515\n",
      "+ Iter:  82 Cost:  0.000563861263221\n",
      "+ Iter:  83 Cost:  0.000574230644372\n",
      "+ Iter:  84 Cost:  0.000569923785385\n",
      "+ Iter:  85 Cost:  0.000555196074447\n",
      "+ Iter:  86 Cost:  0.000538903351149\n",
      "+ Iter:  87 Cost:  0.000527610574658\n",
      "+ Iter:  88 Cost:  0.000522322588181\n",
      "+ Iter:  89 Cost:  0.000520585775579\n",
      "+ Iter:  90 Cost:  0.000520221452089\n",
      "+ Iter:  91 Cost:  0.000521089002434\n",
      "+ Iter:  92 Cost:  0.000523998107137\n",
      "+ Iter:  93 Cost:  0.000528746396686\n",
      "+ Iter:  94 Cost:  0.000533504255635\n",
      "+ Iter:  95 Cost:  0.000535967142278\n",
      "+ Iter:  96 Cost:  0.000535003471693\n",
      "+ Iter:  97 Cost:  0.000531273953951\n",
      "+ Iter:  98 Cost:  0.000526528534146\n",
      "+ Iter:  99 Cost:  0.000522377262441\n",
      "+ Iter:  100 Cost:  0.000519553563765\n",
      "+ Iter:  101 Cost:  0.000518018965399\n",
      "+ Iter:  102 Cost:  0.000517472387901\n",
      "+ Iter:  103 Cost:  0.000517708746193\n",
      "+ Iter:  104 Cost:  0.000518580209003\n",
      "+ Iter:  105 Cost:  0.000519792482192\n",
      "+ Iter:  106 Cost:  0.000520851218416\n",
      "+ Iter:  107 Cost:  0.000521252918896\n",
      "+ Iter:  108 Cost:  0.000520749328902\n",
      "+ Iter:  109 Cost:  0.000519471252207\n",
      "+ Iter:  110 Cost:  0.00051780448186\n",
      "+ Iter:  111 Cost:  0.000516166315808\n",
      "+ Iter:  112 Cost:  0.000514832837344\n",
      "+ Iter:  113 Cost:  0.000513905038397\n",
      "+ Iter:  114 Cost:  0.000513364772295\n",
      "+ Iter:  115 Cost:  0.000513142738919\n",
      "+ Iter:  116 Cost:  0.000513139852192\n",
      "+ Iter:  117 Cost:  0.000513227032804\n",
      "+ Iter:  118 Cost:  0.000513254676621\n",
      "+ Iter:  119 Cost:  0.00051309583123\n",
      "+ Iter:  120 Cost:  0.000512690327496\n",
      "+ Iter:  121 Cost:  0.00051206770294\n",
      "+ Iter:  122 Cost:  0.00051131926137\n",
      "+ Iter:  123 Cost:  0.000510557263641\n",
      "+ Iter:  124 Cost:  0.000509870936597\n",
      "+ Iter:  125 Cost:  0.000509306753147\n",
      "+ Iter:  126 Cost:  0.000508871871898\n",
      "+ Iter:  127 Cost:  0.000508549154919\n",
      "+ Iter:  128 Cost:  0.000508302672301\n",
      "+ Iter:  129 Cost:  0.000508089756534\n",
      "+ Iter:  130 Cost:  0.000507864872803\n",
      "+ Iter:  131 Cost:  0.00050759426679\n",
      "+ Iter:  132 Cost:  0.000507261736109\n",
      "+ Iter:  133 Cost:  0.000506874933292\n",
      "+ Iter:  134 Cost:  0.000506456525521\n",
      "+ Iter:  135 Cost:  0.000506035716082\n",
      "+ Iter:  136 Cost:  0.000505637810474\n",
      "+ Iter:  137 Cost:  0.000505278340883\n",
      "+ Iter:  138 Cost:  0.000504962002243\n",
      "+ Iter:  139 Cost:  0.000504684015297\n",
      "+ Iter:  140 Cost:  0.000504433496674\n",
      "+ Iter:  141 Cost:  0.000504198892433\n",
      "+ Iter:  142 Cost:  0.000503967823063\n",
      "+ Iter:  143 Cost:  0.000503731692006\n",
      "+ Iter:  144 Cost:  0.000503486287677\n",
      "+ Iter:  145 Cost:  0.000503234175019\n",
      "+ Iter:  146 Cost:  0.000502980150848\n",
      "+ Iter:  147 Cost:  0.000502732142053\n",
      "+ Iter:  148 Cost:  0.000502495731926\n",
      "+ Iter:  149 Cost:  0.000502275267964\n",
      "+ Iter:  150 Cost:  0.00050207128629\n",
      "+ Iter:  151 Cost:  0.000501882966673\n",
      "+ Iter:  152 Cost:  0.000501707353525\n",
      "+ Iter:  153 Cost:  0.000501541698205\n",
      "+ Iter:  154 Cost:  0.000501383464952\n",
      "+ Iter:  155 Cost:  0.000501230955476\n",
      "+ Iter:  156 Cost:  0.000501083809937\n",
      "+ Iter:  157 Cost:  0.000500942460657\n",
      "+ Iter:  158 Cost:  0.000500808192316\n",
      "+ Iter:  159 Cost:  0.0005006825987\n",
      "+ Iter:  160 Cost:  0.000500566635398\n",
      "+ Iter:  161 Cost:  0.000500460805428\n",
      "+ Iter:  162 Cost:  0.000500364744439\n",
      "+ Iter:  163 Cost:  0.000500278222513\n",
      "+ Iter:  164 Cost:  0.00050020039045\n",
      "+ Iter:  165 Cost:  0.000500131100993\n",
      "+ Iter:  166 Cost:  0.000500069968719\n",
      "+ Iter:  167 Cost:  0.000500017225631\n",
      "+ Iter:  168 Cost:  0.000500763233369\n",
      "+ Iter:  169 Cost:  0.000551912075794\n",
      "+ Iter:  170 Cost:  0.000589037444246\n",
      "+ Iter:  171 Cost:  0.00066088167388\n",
      "+ Iter:  172 Cost:  0.000655466826144\n",
      "+ Iter:  173 Cost:  0.000640208641914\n",
      "+ Iter:  174 Cost:  0.000580957267552\n",
      "+ Iter:  175 Cost:  0.000533430928265\n",
      "+ Iter:  176 Cost:  0.000502965860957\n",
      "+ Iter:  177 Cost:  0.000503927480511\n",
      "+ Iter:  178 Cost:  0.000528448439418\n",
      "+ Iter:  179 Cost:  0.000558043119852\n",
      "+ Iter:  180 Cost:  0.000578273633653\n",
      "+ Iter:  181 Cost:  0.000577344170658\n",
      "+ Iter:  182 Cost:  0.000558760918885\n",
      "+ Iter:  183 Cost:  0.000531493395983\n",
      "+ Iter:  184 Cost:  0.000509060192299\n",
      "+ Iter:  185 Cost:  0.000500015809655\n",
      "+ Iter:  186 Cost:  0.000505872935338\n",
      "+ Iter:  187 Cost:  0.000520897593165\n",
      "+ Iter:  188 Cost:  0.000535860132189\n",
      "+ Iter:  189 Cost:  0.000543009829956\n",
      "+ Iter:  190 Cost:  0.000539284738796\n",
      "+ Iter:  191 Cost:  0.000527260813133\n",
      "+ Iter:  192 Cost:  0.000512991239462\n",
      "+ Iter:  193 Cost:  0.000502764685516\n",
      "+ Iter:  194 Cost:  0.000500078395164\n",
      "+ Iter:  195 Cost:  0.00050443275944\n",
      "+ Iter:  196 Cost:  0.000512147860765\n",
      "+ Iter:  197 Cost:  0.000518561691554\n",
      "+ Iter:  198 Cost:  0.000520368862209\n",
      "+ Iter:  199 Cost:  0.000516978029209\n",
      "+ Iter:  200 Cost:  0.000510394113802\n",
      "+ Iter:  201 Cost:  0.000503894136778\n",
      "+ Iter:  202 Cost:  0.000500291600293\n",
      "+ Iter:  203 Cost:  0.000500665998494\n",
      "+ Iter:  204 Cost:  0.00050408908364\n",
      "+ Iter:  205 Cost:  0.000508340729444\n",
      "+ Iter:  206 Cost:  0.000511124742902\n",
      "+ Iter:  207 Cost:  0.000511151105923\n",
      "+ Iter:  208 Cost:  0.000508602694084\n",
      "+ Iter:  209 Cost:  0.000504829119686\n",
      "+ Iter:  210 Cost:  0.000501557879736\n",
      "+ Iter:  211 Cost:  0.000500031301672\n",
      "+ Iter:  212 Cost:  0.000500500984182\n",
      "+ Iter:  213 Cost:  0.000502261494516\n",
      "+ Iter:  214 Cost:  0.00050412570833\n",
      "+ Iter:  215 Cost:  0.000505057343256\n",
      "+ Iter:  216 Cost:  0.000504634367613\n",
      "+ Iter:  217 Cost:  0.000503162314324\n",
      "+ Iter:  218 Cost:  0.000501420901924\n",
      "+ Iter:  219 Cost:  0.000500224362894\n",
      "+ Iter:  220 Cost:  0.000500026280342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Iter:  221 Cost:  0.000500751740858\n",
      "+ Iter:  222 Cost:  0.000501902012054\n",
      "+ Iter:  223 Cost:  0.00050284563158\n",
      "+ Iter:  224 Cost:  0.000503129113147\n",
      "+ Iter:  225 Cost:  0.000502662638507\n",
      "+ Iter:  226 Cost:  0.000501713304664\n",
      "+ Iter:  227 Cost:  0.000500726619406\n",
      "+ Iter:  228 Cost:  0.000500098999933\n",
      "+ Iter:  229 Cost:  0.000499999585132\n",
      "+ Iter:  230 Cost:  0.00050032952198\n",
      "+ Iter:  231 Cost:  0.000500810879572\n",
      "+ Iter:  232 Cost:  0.000501145091366\n",
      "+ Iter:  233 Cost:  0.000501159324862\n",
      "+ Iter:  234 Cost:  0.000500867904203\n",
      "+ Iter:  235 Cost:  0.000500438968872\n",
      "+ Iter:  236 Cost:  0.000500089820528\n",
      "+ Iter:  237 Cost:  0.00049997612442\n",
      "+ Iter:  238 Cost:  0.000500122861892\n",
      "+ Iter:  239 Cost:  0.00050042863656\n",
      "+ Iter:  240 Cost:  0.000500728732756\n",
      "+ Iter:  241 Cost:  0.000500879105431\n",
      "+ Iter:  242 Cost:  0.000500820373628\n",
      "+ Iter:  243 Cost:  0.00050059323734\n",
      "+ Iter:  244 Cost:  0.000500306810503\n",
      "+ Iter:  245 Cost:  0.000500077947074\n",
      "+ Iter:  246 Cost:  0.000499978180986\n",
      "+ Iter:  247 Cost:  0.000500008701313\n",
      "+ Iter:  248 Cost:  0.000500112051767\n",
      "+ Iter:  249 Cost:  0.000500209535654\n",
      "+ Iter:  250 Cost:  0.000500241874013\n",
      "+ Iter:  251 Cost:  0.000500195310973\n",
      "+ Iter:  252 Cost:  0.000500100507374\n",
      "+ Iter:  253 Cost:  0.000500011523051\n",
      "+ Iter:  254 Cost:  0.000499975037065\n",
      "+ Iter:  255 Cost:  0.000500008162719\n",
      "+ Iter:  256 Cost:  0.000500092652818\n",
      "+ Iter:  257 Cost:  0.000500187237009\n",
      "+ Iter:  258 Cost:  0.000500249152625\n",
      "+ Iter:  259 Cost:  0.000500253474147\n",
      "+ Iter:  260 Cost:  0.000500202501366\n",
      "+ Iter:  261 Cost:  0.000500120740248\n",
      "+ Iter:  262 Cost:  0.000500041331438\n",
      "+ Iter:  263 Cost:  0.00049998991438\n",
      "+ Iter:  264 Cost:  0.000499975028625\n",
      "+ Iter:  265 Cost:  0.000499987748992\n",
      "+ Iter:  266 Cost:  0.000500009113631\n",
      "+ Iter:  267 Cost:  0.000500021729367\n",
      "+ Iter:  268 Cost:  0.000500017291684\n",
      "+ Iter:  269 Cost:  0.00050000006996\n",
      "+ Iter:  270 Cost:  0.000499981727752\n",
      "+ Iter:  271 Cost:  0.000499975163724\n",
      "+ Iter:  272 Cost:  0.000499986415043\n",
      "+ Iter:  273 Cost:  0.000500012807289\n",
      "+ Iter:  274 Cost:  0.00050004420877\n",
      "+ Iter:  275 Cost:  0.000500068274443\n",
      "+ Iter:  276 Cost:  0.000500076182878\n",
      "+ Iter:  277 Cost:  0.000500065922264\n",
      "+ Iter:  278 Cost:  0.000500042856778\n",
      "+ Iter:  279 Cost:  0.000500015571888\n",
      "+ Iter:  280 Cost:  0.00049999278024\n",
      "+ Iter:  281 Cost:  0.00049997928223\n",
      "+ Iter:  282 Cost:  0.000499975027055\n",
      "+ Iter:  283 Cost:  0.000499976380493\n",
      "+ Iter:  284 Cost:  0.000499978649059\n",
      "Total time in seconds:  2.696611166000366\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    #initiaze opt parameters\n",
    "    (max_iters, threshold, init_qfac, init_rho, learning_rate, init_gamma_val, \n",
    "     gamma_factor, inc_iter, upper_limit_rho) = opt_parameters()\n",
    "\n",
    "    #test your code\n",
    "    solver = TFSolver(gpus = 1)\n",
    "    output_results = solver.solve(A, b, reg_param, max_iters, threshold, \n",
    "                                  init_qfac, init_rho, learning_rate, \n",
    "                                  init_gamma_val, gamma_factor,inc_iter, upper_limit_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.04999308]]\n"
     ]
    }
   ],
   "source": [
    "final_result = np.reshape(np.array(output_results['gamma'])/m,(m*n,1))\n",
    "final_result = np.real(final_result[::m])\n",
    "ind_low = final_result < 1e-8\n",
    "final_result[ind_low] = 0\n",
    "print(final_result) #sparse codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
