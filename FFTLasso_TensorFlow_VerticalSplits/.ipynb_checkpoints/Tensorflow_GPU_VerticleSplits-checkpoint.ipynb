{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introduction\n",
    "The following code solves the LASSO problem in the Fourier Domain.\n",
    "\n",
    "The LASSO:\n",
    "$\\|\\mathbf{A} \\mathbf{c} - \\mathbf{b} \\|_2^2 + \\lambda \\|\\mathbf{c} \\|_1$\n",
    "\n",
    "This is a toy example on how large dictionaries $\\mathbf{A}$ can be distrubted over multiple GPUs. In general tensorflow is significently slower than many other optinos but it is particularly handy for prototyping. This is only a demonstration on the applicability of solving such large sclae problems in a GPU distributed fashion.\n",
    "\n",
    "Refer to \"FFTLasso: Large-Scale LASSO in The Fourier Domain\" for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data and Regularization Parameter Initialization\n",
    "\n",
    "Read data from disk, or simply generate your own gaussian dictionary (A) and test sample (b). Also, the choice of the regularization parameter is set ehre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# #Reading data from disc\n",
    "# matA = spio.loadmat('A.mat')\n",
    "# matb = spio.loadmat('b.mat')\n",
    "# A = matA['A']\n",
    "# b = matb['b']\n",
    "# m,n = A.shape\n",
    "# print(m,n)\n",
    "\n",
    "a = np.arange(20) + 1\n",
    "b = np.arange(21,41)\n",
    "A = np.array([a,b])\n",
    "b = np.array([[1],[2]]).astype(np.float32)\n",
    "m, n = A.shape\n",
    "\n",
    "reg_param = np.array(1e-2).astype(np.float32) #regularization \\lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Optimization parameters\n",
    "\n",
    "In here we initilize the ADMM parameters:\n",
    "\n",
    "1) Maximum number of iterations (max_iters)\n",
    "\n",
    "2) Stopping criterion based on the standard deviation of the last 5 objective values (threshold)\n",
    "\n",
    "3) Update of the dual variables using nesterovs method (Q, init_rho)\n",
    "\n",
    "4) The amound at which the augmentation constant is increased learning_rate (plays role in overall ADMM iteration count)\n",
    "\n",
    "5) The constants regarding nesterovs update and how much is it updated in every iter (init_gamma_val, gamma_factor)\n",
    "\n",
    "6) Every how many iterations do we carry out the updates to rho, init_gamma_cal (inc_iter)\n",
    "\n",
    "7) Maximum permittable rho (upper_limit_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opt_parameters():\n",
    "    max_iters = 1000 #max num iterations \n",
    "    threshold = 1e-8  #stopping criterion\n",
    "    #Nesterov's accelaration\n",
    "    Q = 30;\n",
    "    init_qfac=np.array((np.sqrt(Q)-1)/(np.sqrt(Q)+1)).astype(np.float32) \n",
    "    init_rho  = np.array(1).astype(np.float32) #initial rho\n",
    "    learning_rate = np.array(1).astype(np.float32) #increasing rate of rho\n",
    "    upper_limit_rho = 2000\n",
    "    inc_iter = 1     #upper bound on rho\n",
    "    init_gamma_val = np.array(1).astype(np.float32)  #initial gamma value\n",
    "    gamma_factor = 1 #increasing rate of gamma\n",
    "    \n",
    "    return (max_iters, threshold, init_qfac, init_rho, learning_rate, init_gamma_val, \n",
    "            gamma_factor, inc_iter, upper_limit_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Class of the FFTLasso solver\n",
    "\n",
    "The class FFTLasso has the following methods:\n",
    "\n",
    "1) _initialize: initializes the variables in the optimization along with the overhead data that is used only once.\n",
    "\n",
    "5) fill_feed_dict: collects all the variables output of the optimization into a dictioray to be fed again to the network\n",
    "\n",
    "3) compute_cost: computes the objective value\n",
    "\n",
    "2) _graph: constructs the bulk of the graph for the optimization\n",
    "\n",
    "4) solve: solves the optimization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TFSolver(object):\n",
    "    def __init__(self, gpus=1):\n",
    "        self._gpus = gpus\n",
    "        \n",
    "################################################################\n",
    "                    #Initlize the variables\n",
    "################################################################\n",
    "\n",
    "    def _initialize(self, A, b, rho):\n",
    "        #break A_into piaces\n",
    "        A_all = self.break_A_pieces(A,self._gpus)\n",
    "        n_new = int(A.shape[1]/self._gpus)\n",
    "        #dual variable intialization in Foureri Domain\n",
    "        b_hat_conj = (np.fft.ifft(b.T).T).astype(np.complex64)\n",
    "        init_psi_hat_conj = (np.fft.ifft(np.zeros([m,1]).T).T).astype(np.complex64)\n",
    "        A_hat = [None] * self._gpus\n",
    "        A_hat_conj = [None] * self._gpus\n",
    "        corr_A_lists = [None] * self._gpus\n",
    "        init_theta = [None] * self._gpus\n",
    "        init_gamma = [None] * self._gpus\n",
    "        temp = [None] * self._gpus\n",
    "        init_zeta = [None] * self._gpus\n",
    "        \n",
    "        for i in range(self._gpus):\n",
    "            #Data related initialization\n",
    "            A_hat[i] = (np.fft.fft(A_all[i].T).T).astype(np.complex64)\n",
    "            A_hat_conj[i] = (np.fft.ifft(A_all[i].T).T).astype(np.complex64) # = np.conj(A_hat)/m\n",
    "             #constraints variable intilization\n",
    "            init_theta[i] = (np.zeros([m*n_new,1])).astype(np.float32)\n",
    "             #primal variable inilization\n",
    "            init_gamma[i] = (np.zeros([m*n_new,1])).astype(np.float32)\n",
    "            #init zeta\n",
    "            temp[i] = np.real(np.reshape(np.fft.fft((A_hat[i]*init_psi_hat_conj).T).T,(m*n_new,1))).astype(np.float32)\n",
    "            init_zeta[i] = (temp[i] + init_theta[i] + (init_gamma[i]))\n",
    "            \n",
    "        init_gamma_out = (np.zeros([n,1])).astype(np.float32)\n",
    "        mask_update = np.ones([m,n]).astype(np.float32)\n",
    "        mask_update[0] = 0\n",
    "        mask_update = np.split(mask_update,self._gpus,1)\n",
    "        corr_A = np.array(np.zeros([m,1]).T).T\n",
    "        for i in range(self._gpus):\n",
    "            corr_A = corr_A + np.reshape((np.real(np.sum(A_hat[i]*A_hat_conj[i],1))),(-1,1))\n",
    "            mask_update[i] = np.reshape(mask_update[i].T,(-1,1))\n",
    "            \n",
    "        \n",
    "        if(self._gpus > 1):\n",
    "            e = np.array(init_zeta)-np.array(init_theta)-np.array(init_gamma)\n",
    "            e_hat_conj  =(np.fft.ifft(np.reshape(e,(n,m)))).T  \n",
    "            ccc = np.array(A_hat_conj)\n",
    "            Ahat_conj_complete = ccc.reshape(ccc.shape[1],ccc.shape[0]*ccc.shape[2])\n",
    "            upper = np.reshape(np.sum(Ahat_conj_complete* np.array(e_hat_conj),axis=1),(m,1)) + b_hat_conj\n",
    "            lower = (rho * np.array(corr_A)) + 1.0\n",
    "            init_psi_hat_conj = upper / lower \n",
    "        else:\n",
    "            e = np.array(init_zeta)-np.array(init_theta)-np.array(init_gamma)\n",
    "            e_hat_conj  =(np.fft.ifft(np.reshape(e,(n,m)))).T  \n",
    "            upper = np.reshape(np.sum(np.reshape(np.array(A_hat_conj)* np.array(e_hat_conj),(m,n_new)),axis = 1),(-1,1)) + b_hat_conj\n",
    "            lower = (rho * np.array(corr_A)) + 1.0\n",
    "            init_psi_hat_conj = upper / lower\n",
    "            \n",
    "\n",
    "        diff_value = np.inf #error difference  \n",
    "    \n",
    "        \n",
    "        return(A_hat, corr_A, b_hat_conj, init_psi_hat_conj, init_theta, init_zeta, init_gamma, \n",
    "               init_gamma_out, mask_update)\n",
    "    \n",
    "################################################################\n",
    "        #Collects all variables into a dictionary\n",
    "################################################################\n",
    "    \n",
    "    \n",
    "    def fill_feed_dict(self,values):\n",
    "        feed_dict = { }\n",
    "        for i in range(self._gpus):\n",
    "            feed_dict[self.psi_hat_conj[i]] =  values[\"psi_hat_conj\"]\n",
    "            feed_dict[self.theta[i]] =  values[\"theta\"][i]\n",
    "            feed_dict[self.zeta[i]] =  values[\"zeta\"][i]\n",
    "            feed_dict[self.gamma[i]] =  values[\"gamma\"][i]\n",
    "            feed_dict[self.rho[i]] =  values[\"rho\"][0]\n",
    "            feed_dict[self.gamma_val[i]] =  values[\"gamma_val\"][0]\n",
    "\n",
    "        return feed_dict\n",
    "    \n",
    "################################################################\n",
    "        #Break bulky dictionary to pieces\n",
    "################################################################    \n",
    "    def break_A_pieces(self, A,num_gpus):\n",
    "        return np.split(A,num_gpus,1)\n",
    "\n",
    "################################################################\n",
    "        #Computes objectove value\n",
    "################################################################    \n",
    "    \n",
    "    def compute_cost(self, A,b,c,lamb):\n",
    "        m,n = A.shape\n",
    "        c = np.reshape(np.array(c),(m*n,1))\n",
    "        c=np.real(c[::m]/m)\n",
    "        return 0.5*(np.sum((np.dot(A,c) - b)**2)) + lamb*np.sum(np.abs(c))\n",
    "    \n",
    "################################################################\n",
    "        #Bulding the graph of 1 iteration\n",
    "################################################################   \n",
    "    \n",
    "    def _graph(self, init_A, init_b, init_A_hat, init_corr_aa, init_b_hat_conj, init_theta, init_zeta, \n",
    "               init_gamma, init_gamma_out, init_lamb, init_qfac, init_rho, init_gamma_val, init_mask_update):\n",
    "\n",
    "        self.psi_hat_conj = [None]*self._gpus\n",
    "        self.theta = [None]*self._gpus\n",
    "        self.zeta = [None]*self._gpus\n",
    "        self.gamma = [None]*self._gpus\n",
    "        self.gamma_out = [None]*self._gpus\n",
    "        self.rho = [None]*self._gpus\n",
    "        self.gamma_val = [None]*self._gpus\n",
    "\n",
    "        self.theta_o = [None]*self._gpus\n",
    "        self.zeta_o = [None]*self._gpus\n",
    "        self.gamma_o = [None]*self._gpus\n",
    "        self.gamma_out_o = [None]*self._gpus\n",
    "        self.rho_o = [None]*self._gpus\n",
    "        self.gamma_val_o = [None]*self._gpus\n",
    "        self.upper_o = [None]*self._gpus\n",
    "\n",
    "        n_new = int(init_A.shape[1]/self._gpus)\n",
    "        m_new = int(init_A.shape[0])\n",
    "        \n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():      \n",
    "            for i in range(self._gpus):\n",
    "                print(\"################################################################\")\n",
    "                with tf.device('/gpu:' + str(i)):           \n",
    "                    with tf.variable_scope('constants_'+str(i)):\n",
    "                        print(\"Transfering Constant Data to GPU\" + str(i), end=\"\")\n",
    "                        A_hat = tf.constant(init_A_hat[i],tf.complex64, name='A_hat')\n",
    "                        mask_update = tf.constant(init_mask_update[i],tf.float32, name = 'mask')\n",
    "                        lamb = tf.constant(init_lamb,tf.float32, name = 'lambda')\n",
    "                        qfac = tf.constant(init_qfac, name = 'Nesterovs_qfac')\n",
    "                        corr_A = tf.constant(init_corr_aa, tf.float32, name='corr_aa')\n",
    "                        b = tf.constant(init_b,tf.float32, name = 'b')\n",
    "                        b_hat_conj = tf.constant(init_b_hat_conj, tf.complex64, name='b_hat_conj')\n",
    "                        print(\": Done.\")\n",
    "                        \n",
    "                    with tf.variable_scope('variables_inputs_pl_'+str(i)):\n",
    "                        print(\"Initlization Place Holders on GPU\"  + str(i), end=\"\")\n",
    "                        self.psi_hat_conj[i] = tf.placeholder(tf.complex64, name = 'pl_psi_hat_conj')\n",
    "                        self.theta[i] = tf.placeholder(tf.float32, name = 'pl_theta')\n",
    "                        self.zeta[i] = tf.placeholder(tf.float32,  name = 'pl_zeta')\n",
    "                        self.gamma[i] = tf.placeholder(tf.float32, name = 'pl_gamma')\n",
    "                        self.rho[i] = tf.placeholder(tf.float32, name = 'pl_rho')            \n",
    "                        self.gamma_val[i] = tf.placeholder(tf.float32, name = 'pl_gamma_val')\n",
    "                        print(\": Done.\")\n",
    "                        \n",
    "                    with tf.variable_scope('variables_outputs_pl_'+str(i)):  \n",
    "                        self.theta_o[i] = self.theta[i] \n",
    "                        self.zeta_o[i] = self.zeta[i] \n",
    "                        self.gamma_o[i] = self.gamma[i] \n",
    "                        self.rho_o[i] = self.rho[i] \n",
    "                        self.gamma_val_o[i] = self.gamma_val[i]    \n",
    "                        \n",
    "                print(\"Generating Compute Graph on GPU\"  + str(i), end=\"\")\n",
    "                #theta_o update\n",
    "                with tf.name_scope('Theta_Update'):\n",
    "                    temp = tf.real(tf.reshape(tf.fft(tf.transpose(tf.multiply(A_hat, self.psi_hat_conj[i]))),(m_new*n_new,1)))\n",
    "                    self.theta_o[i] = self.zeta_o[i]-self.gamma_o[i]/self.rho_o[i]- temp\n",
    "                    self.theta_o[i] = self.theta_o[i] * mask_update\n",
    "\n",
    "                #zeta_o update\n",
    "                with tf.name_scope('Zeta_Update'):\n",
    "                    self.zeta_o[i] = temp+(self.theta_o[i])+(self.gamma_o[i]/self.rho_o[i])\n",
    "                    self.zeta_o[i] = tf.minimum(lamb,tf.abs(self.zeta_o[i])) * tf.sign(self.zeta_o[i])\n",
    "    \n",
    "    \n",
    "                #gamma_o update\n",
    "                with tf.name_scope('Gamma_Update'):\n",
    "                    gamma0_o=self.gamma_o[i];\n",
    "                    self.gamma_o[i] = (self.gamma_o[i] + (self.gamma_val_o[i]*self.rho_o[i])*( temp + (self.theta_o[i])-self.zeta_o[i]))\n",
    "                    self.gamma_o[i]=(1+qfac)*self.gamma_o[i]-qfac*gamma0_o; \n",
    "                    tf.summary.histogram('Gamm_Output', self.gamma_o[i])\n",
    "\n",
    "                #Psi update\n",
    "                with tf.name_scope('Upper_update_for_CPUPsi'):\n",
    "                    e = tf.cast(self.rho_o[i]*self.zeta_o[i]-self.rho_o[i]*self.theta_o[i]-self.gamma_o[i],tf.complex64)\n",
    "                    e_hat_conj  = tf.transpose(tf.ifft(tf.reshape(e,(n_new,m_new))))  \n",
    "#                     self.upper_o[i] = tf.reshape(tf.reduce_sum(A_hat_conj* e_hat_conj,1),[m_new,1])\n",
    "                    self.upper_o[i] = tf.reshape(tf.reduce_sum(tf.conj(A_hat)/m_new* e_hat_conj,1),[m_new,1])\n",
    "\n",
    "                print(\": Done.\")\n",
    "                    \n",
    "                    \n",
    "                self.merged = tf.summary.merge_all()\n",
    "                \n",
    "        print(\"################################################################\")\n",
    "   \n",
    "        outputs = {\"theta\": self.theta_o,\n",
    "                    \"zeta\": self.zeta_o,\n",
    "                    \"gamma\": self.gamma_o,\n",
    "                    \"rho\": self.rho_o,\n",
    "                    \"gamma_val\": self.gamma_val_o,\n",
    "                    \"upper\": self.upper_o,\n",
    "                  }\n",
    "\n",
    "        return graph,outputs    \n",
    "    \n",
    "################################################################\n",
    "                #Solving the Lasso\n",
    "################################################################         \n",
    "\n",
    "    def solve(self, A, b, reg_param, max_iters, threshold, \n",
    "                                  qfac, rho, learning_rate, \n",
    "                                  gamma_val, gamma_factor,inc_iter, upper_limit_rho):\n",
    "        \n",
    "        \n",
    "        (A_hat, corr_A, b_hat_conj, init_psi_hat_conj, theta, zeta, gamma, gamma_out, \n",
    "         mask_update) = self._initialize(A, b, rho)        \n",
    "        #Done initlization\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        print('Graph Generation ...')    \n",
    "        graph, outputs_nodes = self._graph(A, b, A_hat, corr_A, b_hat_conj, \n",
    "                                           theta, zeta, gamma, gamma_out, reg_param, \n",
    "                                           qfac, rho, gamma_val, mask_update)\n",
    "        \n",
    "        \n",
    "        init_values = {\"psi_hat_conj\": init_psi_hat_conj,\n",
    "                        \"theta\": theta,\n",
    "                        \"zeta\": zeta,\n",
    "                        \"gamma\": gamma,\n",
    "                        \"rho\": [rho],\n",
    "                        \"gamma_val\": [gamma_val],\n",
    "                        }\n",
    "        \n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            iteration_writer = tf.summary.FileWriter('./logs/1', sess.graph)\n",
    "            \n",
    "            # first iteration:\n",
    "            feed_dict = self.fill_feed_dict(init_values) \n",
    "            output_results = sess.run(outputs_nodes, feed_dict=feed_dict)            \n",
    "            cost = [self.compute_cost(A,b,output_results[\"gamma\"],reg_param)]\n",
    "            print(\"+ Iter: \", 1, 'Cost: ', cost[-1])\n",
    "                \n",
    "            # CPU for each upper and rho get phi_hat_conj for all gpus\n",
    "            sum_upper = np.zeros_like(output_results[\"upper\"][0]) + b_hat_conj\n",
    "            for upper in output_results[\"upper\"]:\n",
    "                sum_upper += upper\n",
    "            \n",
    "            lower = (output_results[\"rho\"][0]*corr_A) + 1.0\n",
    "            output_results[\"psi_hat_conj\"] = sum_upper / lower\n",
    "            \n",
    "################################################################\n",
    "                #Main Loop\n",
    "################################################################  \n",
    "            start_time = time.time()\n",
    "            for iteration in range(2,max_iters+1):\n",
    "                feed_dict = self.fill_feed_dict(output_results)\n",
    "                summary_new, output_results = sess.run([self.merged,outputs_nodes], feed_dict=feed_dict)\n",
    "                iteration_writer.add_summary(summary_new,iteration)\n",
    "                \n",
    "                # CPU for each upper and rho get phi_hat_conj for all gpus\n",
    "                sum_upper = np.zeros_like(output_results[\"upper\"][0]) + b_hat_conj\n",
    "                for upper in output_results[\"upper\"]:\n",
    "                    sum_upper += upper\n",
    "                lower = (np.array(output_results[\"rho\"][0])*corr_A)+ 1.0\n",
    "                output_results[\"psi_hat_conj\"] = sum_upper / lower\n",
    "\n",
    "                if iteration % 1 == 0:\n",
    "                    cost.append(self.compute_cost(A,b,output_results[\"gamma\"],reg_param))  \n",
    "                    print(\"+ Iter: \", iteration, 'Cost: ', cost[-1])\n",
    "                    \n",
    "                    if(np.std(np.array(cost[-5:])) < threshold):\n",
    "                        break\n",
    "                        \n",
    "                    if  iteration % inc_iter == 0:\n",
    "                        if(output_results[\"rho\"][0] <= upper_limit_rho):\n",
    "                            output_results[\"rho\"] = [output_results[\"rho\"][0]*learning_rate] * self._gpus\n",
    "  \n",
    "                    \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Total time in seconds: ', elapsed_time)\n",
    "        return output_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main Code\n",
    "\n",
    "- Specify the number of GPUs as input to TFSolver(.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':  \n",
    "    #initiaze opt parameters\n",
    "    (max_iters, threshold, init_qfac, init_rho, learning_rate, init_gamma_val, \n",
    "     gamma_factor, inc_iter, upper_limit_rho) = opt_parameters()\n",
    "\n",
    "    #test your code\n",
    "    solver = TFSolver(gpus = 1)\n",
    "    output_results = solver.solve(A, b, reg_param, max_iters, threshold, \n",
    "                                  init_qfac, init_rho, learning_rate, \n",
    "                                  init_gamma_val, gamma_factor,inc_iter, upper_limit_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_result = np.reshape(np.array(output_results['gamma'])/m,(m*n,1))\n",
    "final_result = np.real(final_result[::m])\n",
    "ind_low = final_result < 1e-8\n",
    "final_result[ind_low] = 0\n",
    "print(final_result) #sparse codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
